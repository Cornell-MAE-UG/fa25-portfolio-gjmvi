---
layout: project
title: Boeing 737 Ethical Analysis Report
description: Summary of assignments from Weeks 6-9
technologies: [None]

---

Report:
The Boeing 737 MAX disaster represents a failure that extends far beyond a single erroneous system. While the MCAS and its reliance on a single AoA sensor were the focal points of the issue, the larger ethical problems lie in how engineering decisions were made, communicated, and approved within the corporate workplace. At its core, the case displays the internal priorities of professional engineers, as well as the organizations they work for. From a technical standpoint, MCAS violated long established principles of a safe and verified design. The system was given significant control over aircraft pitch while relying on input from a single sensor, one that was not intended for a passenger craft in the first place, creating an irresponsible and avoidable weak point. In aviation, and engineering more broadly, redundancy is a critical safeguard in every aspect; no one part is perfect. The ethical problem is not simply that MCAS malfunctioned, but that its architecture reflected an acceptance of known risk in exchange for reduced cost, simplified certification, and minimal pilot retraining. These decisions carried foreseeable consequences, and were made purely to save costs and time in the engineering process. The resulting loss of pilot control was not an unforeseeable accident, but a very possible outcome. The lack of documentation and significance in the manual only exacerbated this. Equally significant was the failure of truthful and effective communication. Pilots were not adequately informed of MCAS’s existence or its operation in any amount. Even after the first occurrence of trouble, Boeing made sure to cover its mistakes rather than inform the airlines of its faulty and clandestine system. While Boeing may have met narrow regulatory disclosure requirements, ethical transparency demands more than legal compliance. The FAA deferral of regulatory tasks to Boeing employees allowed such events, and brought clarity to the internal turbulence within the governing body. When safety-critical behavior is hidden or minimized to preserve marketing claims, engineers and organizations shift risk onto unwitting stakeholders. In this case, pilots, airlines, and ultimately passengers bore the consequences of decisions made without their informed consent, or possibility of knowledge. Ethical engineering requires that those affected by risk be given the knowledge necessary to understand and manage it, and at the very least to the operators.  The role of individuals within Boeing further complicates the ethical landscape. Engineers involved in MCAS development and certification operated within hierarchical structures that limited individual agency. Internal emails show that concerns were raised, and promptly dismissed. This exemplifies the difficult balance between engineer autonomy and conformation to workplace practices. Some likely recognized the dangers posed by single-sensor dependency or escalating system authority, and the singular test pilot noted irregularities in sim flights. The Boeing culture was clear that of fear and dependence, only passing along the tasks as told. Ethical responsibility does not vanish under diverse priorities, but real-world conditions help explain why the correct actions are difficult to take. This tension highlights the difference between individual culpability and systemic failure: while individuals make decisions, systems shape which decisions feel possible or permissible.  Organizational culture played a decisive role. Boeing’s historical identity as an engineering-driven company had frayed under competitive pressure from Airbus, and increasing emphasis on cost control and schedule adherence. Safety decisions were increasingly framed as obstacles to market competitiveness, rather than non-negotiable ethical commitments.  Ultimately, the Boeing 737 MAX tragedies demonstrate that ethical failures in engineering rarely arise from a single bad decision. They emerge from interacting technical choices, organizational incentives, regulatory structures, which all tie back to human limitations. Preventing similar disasters requires action at multiple levels, empowering individual engineers through ethics training and whistleblower protections, restructuring organizations to give safety measures full authority over schedule and profit, and strengthening regulatory systems to ensure genuine oversight rather than delegated self-certification. Most importantly, the case reaffirms a key ethical principle of engineering: when human lives are at stake, no amount of economic or competitive pressure can justify compromising safety. Anything less than this undermines public trust in engineering itself, and the profession as a whole. 


